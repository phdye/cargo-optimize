//! Stress tests for extreme conditions

use cargo_optimize::{Config, OptimizationLevel, analyzer::*, detector::*, optimizer::*};
use std::sync::{Arc, Mutex};
use std::thread;
use std::time::{Duration, Instant};
use tempfile::TempDir;
use std::fs;

#[test]
fn stress_large_project() {
    let temp_dir = TempDir::new().unwrap();
    let project_root = temp_dir.path();
    
    // Create a very large project structure
    let cargo_toml = r#"
[workspace]
members = [
    "crate_*"
]

[workspace.package]
version = "0.1.0"
edition = "2021"
"#;
    
    // Create workspace with many members
    let member_list: Vec<String> = (0..50)
        .map(|i| format!("\"crate_{}\"", i))
        .collect();
    let cargo_toml = cargo_toml.replace("\"crate_*\"", &member_list.join(",\n    "));
    
    fs::write(project_root.join("Cargo.toml"), cargo_toml).unwrap();
    
    // Create all member crates with many files each
    for i in 0..50 {
        let crate_dir = project_root.join(format!("crate_{}", i));
        let src_dir = crate_dir.join("src");
        fs::create_dir_all(&src_dir).unwrap();
        
        let crate_toml = format!(r#"
[package]
name = "crate_{}"
version.workspace = true
edition.workspace = true

[dependencies]
"#, i);
        fs::write(crate_dir.join("Cargo.toml"), crate_toml).unwrap();
        
        // Create many source files
        for j in 0..20 {
            let content = format!(
                "// Crate {} Module {}\n{}",
                i, j,
                "pub fn test() { println!(\"test\"); }\n".repeat(100)
            );
            fs::write(src_dir.join(format!("mod_{}.rs", j)), content).unwrap();
        }
        
        let lib_rs = (0..20)
            .map(|j| format!("pub mod mod_{};", j))
            .collect::<Vec<_>>()
            .join("\n");
        fs::write(src_dir.join("lib.rs"), lib_rs).unwrap();
    }
    
    // Analyze this massive project
    let start = Instant::now();
    let analysis = ProjectAnalysis::analyze(project_root).unwrap();
    let duration = start.elapsed();
    
    println!("Large project analysis:");
    println!("  - {} crates", analysis.crate_count());
    println!("  - {} lines of code", analysis.code_stats.rust_lines);
    println!("  - {} files", analysis.code_stats.rust_files);
    println!("  - Took {:?}", duration);
    
    assert!(analysis.crate_count() == 50);
    assert!(analysis.code_stats.rust_files >= 1000); // 50 crates * 20 files
    assert!(duration < Duration::from_secs(30), "Analysis too slow: {:?}", duration);
}

#[test]
fn stress_concurrent_access() {
    let config = Arc::new(Mutex::new(Config::new()));
    let mut handles = Vec::new();
    let iterations = 100;
    let thread_count = 10;
    
    for thread_id in 0..thread_count {
        let config_clone = Arc::clone(&config);
        
        let handle = thread::spawn(move || {
            for i in 0..iterations {
                // Read
                {
                    let cfg = config_clone.lock().unwrap();
                    let _ = cfg.optimization_level;
                    let _ = cfg.parallel_jobs;
                }
                
                // Write
                {
                    let mut cfg = config_clone.lock().unwrap();
                    cfg.set_parallel_jobs((thread_id * iterations + i) % 64);
                }
                
                // Serialize
                {
                    let cfg = config_clone.lock().unwrap();
                    let _ = toml::to_string(&*cfg);
                }
            }
        });
        
        handles.push(handle);
    }
    
    // Wait for all threads
    for handle in handles {
        handle.join().expect("Thread panicked");
    }
    
    // Verify final state is consistent
    let final_config = config.lock().unwrap();
    assert!(final_config.parallel_jobs.is_some());
}

#[test]
fn stress_memory_allocation() {
    let mut configs = Vec::new();
    let mut stats_collection = Vec::new();
    
    // Allocate many large structures
    for i in 0..1000 {
        let mut config = Config::new();
        
        // Add many flags
        for j in 0..100 {
            config.extra_cargo_flags.push(format!("--flag-{}-{}", i, j));
            config.extra_rustc_flags.push(format!("-C opt-{}-{}", i, j));
        }
        
        configs.push(config);
        
        // Create large stats
        let mut stats = CodeStats::default();
        stats.rust_lines = i * 1000;
        stats.rust_files = i * 10;
        stats.test_lines = i * 500;
        stats_collection.push(stats);
    }
    
    // Ensure we can still operate
    assert_eq!(configs.len(), 1000);
    assert_eq!(stats_collection.len(), 1000);
    
    // Serialize all configs (stress test serialization)
    for config in &configs {
        let _ = toml::to_string(config).unwrap();
    }
}

#[test]
fn stress_rapid_config_changes() {
    let mut config = Config::new();
    let start = Instant::now();
    let iterations = 10_000;
    
    for i in 0..iterations {
        // Rapidly change configuration
        config.set_optimization_level(match i % 4 {
            0 => OptimizationLevel::Conservative,
            1 => OptimizationLevel::Balanced,
            2 => OptimizationLevel::Aggressive,
            _ => OptimizationLevel::Custom,
        });
        
        config.set_parallel_jobs(i % 64);
        config.auto_detect_hardware = i % 2 == 0;
        config.verbose = i % 3 == 0;
        config.dry_run = i % 5 == 0;
        
        if i % 10 == 0 {
            config.extra_cargo_flags.clear();
        } else {
            config.extra_cargo_flags.push(format!("--flag-{}", i));
        }
    }
    
    let duration = start.elapsed();
    let per_iteration = duration / iterations;
    
    println!("Rapid config changes: {:?} per iteration", per_iteration);
    assert!(per_iteration < Duration::from_micros(100),
           "Config changes too slow: {:?}", per_iteration);
}

#[test]
fn stress_file_system_operations() {
    let temp_dir = TempDir::new().unwrap();
    let iterations = 100;
    
    for i in 0..iterations {
        let config = Config::new();
        let path = temp_dir.path().join(format!("config_{}.toml", i));
        
        // Save
        config.save(&path).unwrap();
        
        // Load
        let loaded = Config::from_file(&path).unwrap();
        
        // Modify and save again
        let mut modified = loaded;
        modified.set_parallel_jobs(i);
        modified.save(&path).unwrap();
        
        // Delete
        fs::remove_file(&path).unwrap();
    }
    
    // Create and analyze many projects
    for i in 0..10 {
        let project_dir = temp_dir.path().join(format!("project_{}", i));
        fs::create_dir_all(&project_dir).unwrap();
        
        let cargo_toml = format!(r#"
[package]
name = "stress_test_{}"
version = "0.1.0"
edition = "2021"
"#, i);
        fs::write(project_dir.join("Cargo.toml"), cargo_toml).unwrap();
        
        let src_dir = project_dir.join("src");
        fs::create_dir_all(&src_dir).unwrap();
        
        // Create many files
        for j in 0..50 {
            let content = format!("// File {}\n", j) + &"fn test() {}\n".repeat(100);
            fs::write(src_dir.join(format!("file_{}.rs", j)), content).unwrap();
        }
        
        // Analyze
        let _ = ProjectAnalysis::analyze(&project_dir);
    }
}

#[test]
fn stress_dependency_graph() {
    // Create a project with massive dependency tree
    let mut dependencies = DependencyAnalysis {
        total_dependencies: 500,
        direct_dependencies: 100,
        transitive_dependencies: 400,
        proc_macro_count: 50,
        categories: Default::default(),
        heavy_dependencies: (0..20).map(|i| format!("heavy_{}", i)).collect(),
        has_heavy_dependencies: true,
        duplicates: (0..30).map(|i| DuplicateDependency {
            name: format!("dup_{}", i),
            versions: vec!["1.0.0".to_string(), "1.0.1".to_string(), "2.0.0".to_string()],
        }).collect(),
    };
    
    // Stress test analysis functions
    for _ in 0..1000 {
        let _ = dependencies.needs_optimization();
    }
    
    assert!(dependencies.needs_optimization());
    assert_eq!(dependencies.duplicates.len(), 30);
}

#[test]
fn stress_complexity_calculation() {
    let metadata = ProjectMetadata {
        name: "stress".to_string(),
        version: "0.1.0".to_string(),
        root_path: std::path::PathBuf::from("."),
        is_workspace: true,
        workspace_members: (0..100).map(|i| format!("member_{}", i)).collect(),
        cargo_metadata: Default::default(),
    };
    
    let code_stats = CodeStats {
        total_lines: 1_000_000,
        rust_lines: 900_000,
        rust_files: 5_000,
        test_lines: 100_000,
        test_files: 500,
        bench_lines: 10_000,
        bench_files: 50,
        example_lines: 5_000,
        example_files: 25,
    };
    
    let dependencies = DependencyAnalysis {
        total_dependencies: 1000,
        direct_dependencies: 200,
        transitive_dependencies: 800,
        proc_macro_count: 100,
        categories: Default::default(),
        heavy_dependencies: vec!["tokio".to_string(); 50],
        has_heavy_dependencies: true,
        duplicates: vec![],
    };
    
    let start = Instant::now();
    
    for _ in 0..10_000 {
        let complexity = BuildComplexity::calculate(&metadata, &code_stats, &dependencies);
        assert!(complexity.score <= 100);
        assert!(complexity.is_complex);
        assert!(complexity.is_large_project);
    }
    
    let duration = start.elapsed();
    println!("10,000 complexity calculations took: {:?}", duration);
    assert!(duration < Duration::from_secs(1));
}

#[test]
fn stress_concurrent_analysis() {
    let temp_dir = TempDir::new().unwrap();
    let project_root = temp_dir.path();
    
    // Create a project
    let cargo_toml = r#"
[package]
name = "concurrent_test"
version = "0.1.0"
edition = "2021"
"#;
    fs::write(project_root.join("Cargo.toml"), cargo_toml).unwrap();
    fs::create_dir_all(project_root.join("src")).unwrap();
    fs::write(project_root.join("src/lib.rs"), "// Test\n").unwrap();
    
    let project_root = Arc::new(project_root.to_path_buf());
    let mut handles = Vec::new();
    
    // Launch many concurrent analyses
    for _ in 0..20 {
        let root = Arc::clone(&project_root);
        let handle = thread::spawn(move || {
            for _ in 0..10 {
                let analysis = ProjectAnalysis::analyze(&*root).unwrap();
                assert!(analysis.metadata.name == "concurrent_test");
            }
        });
        handles.push(handle);
    }
    
    for handle in handles {
        handle.join().expect("Thread panicked");
    }
}

#[test]
fn stress_optimization_combinations() {
    // Test all possible combinations of optimization settings
    let bools = [false, true];
    let levels = [
        OptimizationLevel::Conservative,
        OptimizationLevel::Balanced,
        OptimizationLevel::Aggressive,
        OptimizationLevel::Custom,
    ];
    let jobs = [None, Some(1), Some(4), Some(8), Some(16), Some(32)];
    
    let mut count = 0;
    
    for level in &levels {
        for auto_detect in &bools {
            for analyze in &bools {
                for linker in &bools {
                    for cache in &bools {
                        for job in &jobs {
                            for incremental in &bools {
                                for split in &bools {
                                    let mut config = Config::new();
                                    config.optimization_level = *level;
                                    config.auto_detect_hardware = *auto_detect;
                                    config.analyze_project = *analyze;
                                    config.optimize_linker = *linker;
                                    config.enable_cache = *cache;
                                    config.parallel_jobs = *job;
                                    config.incremental = *incremental;
                                    config.split_debuginfo = *split;
                                    
                                    // Ensure serialization works
                                    let _ = toml::to_string(&config).unwrap();
                                    count += 1;
                                }
                            }
                        }
                    }
                }
            }
        }
    }
    
    println!("Tested {} configuration combinations", count);
    assert!(count == 4 * 2 * 2 * 2 * 2 * 6 * 2 * 2); // All combinations
}

#[test]
fn stress_sustained_load() {
    let start_time = Instant::now();
    let duration = Duration::from_secs(5); // Run for 5 seconds
    let mut operations = 0;
    
    while start_time.elapsed() < duration {
        // Mix of operations
        let config = Config::new();
        let _ = toml::to_string(&config);
        
        let mut stats = CodeStats::default();
        stats.rust_lines = operations * 100;
        let _ = stats.is_large();
        
        let detector = SystemDetector::new();
        let _ = detector.detect_cpu();
        
        operations += 1;
    }
    
    println!("Completed {} operations in {:?}", operations, duration);
    assert!(operations > 1000, "Too few operations completed: {}", operations);
}

#[test] 
fn stress_edge_case_values() {
    // Test with extreme values
    let mut config = Config::new();
    config.set_parallel_jobs(usize::MAX);
    assert_eq!(config.parallel_jobs, Some(usize::MAX));
    
    let mut stats = CodeStats::default();
    stats.rust_lines = usize::MAX;
    stats.test_lines = usize::MAX;
    assert!(stats.is_large());
    assert!(stats.is_test_heavy());
    
    // Test with zero values
    stats.rust_lines = 0;
    stats.test_lines = 0;
    assert!(!stats.is_large());
    assert!(!stats.is_test_heavy());
}

#[test]
fn stress_recursive_structures() {
    let temp_dir = TempDir::new().unwrap();
    let base = temp_dir.path();
    
    // Create deeply nested directory structure
    let mut current = base.to_path_buf();
    for i in 0..50 {
        current = current.join(format!("level_{}", i));
        fs::create_dir(&current).unwrap();
        
        // Add some files at each level
        for j in 0..5 {
            fs::write(
                current.join(format!("file_{}.rs", j)),
                format!("// Level {} File {}\n", i, j)
            ).unwrap();
        }
    }
    
    // Try to analyze this deep structure
    let stats = CodeStats::calculate(base);
    assert!(stats.is_ok());
    
    let stats = stats.unwrap();
    assert!(stats.rust_files == 250); // 50 levels * 5 files
}

#[test]
fn stress_parallel_optimization() {
    let temp_dir = TempDir::new().unwrap();
    let mut handles = Vec::new();
    
    for i in 0..10 {
        let dir = temp_dir.path().join(format!("project_{}", i));
        
        let handle = thread::spawn(move || {
            // Create project
            fs::create_dir_all(&dir).unwrap();
            let cargo_toml = format!(r#"
[package]
name = "parallel_{}"
version = "0.1.0"
edition = "2021"
"#, i);
            fs::write(dir.join("Cargo.toml"), cargo_toml).unwrap();
            fs::create_dir_all(dir.join("src")).unwrap();
            fs::write(dir.join("src/lib.rs"), "// Lib\n").unwrap();
            
            // Optimize
            let mut config = Config::new();
            config.dry_run();
            
            let mut optimizer = Optimizer::with_config(&dir, config).unwrap();
            optimizer.optimize().unwrap();
        });
        
        handles.push(handle);
    }
    
    for handle in handles {
        handle.join().expect("Thread panicked");
    }
}
